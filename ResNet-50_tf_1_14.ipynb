{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import resnet50,sys,os\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from keras import backend as K\n",
    "import tables\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_weights_dir = os.path.expanduser(\"/home/david/Storage/dataset_Tom/weights-floatingpoint-224x224-fixval-best\")\n",
    "saved_model_dir = os.path.expanduser(\"/home/david/Storage/dataset_Tom/weights-floatingpoint-224x224-fixval-best/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_rgb(images): \n",
    "    #normalize image to 0-255 per image.\n",
    "    image_sum = 1/np.sum(np.sum(images,axis=1),axis=-1)\n",
    "    given_axis = 0\n",
    "    # Create an array which would be used to reshape 1D array, b to have \n",
    "    # singleton dimensions except for the given axis where we would put -1 \n",
    "    # signifying to use the entire length of elements along that axis  \n",
    "    dim_array = np.ones((1,images.ndim),int).ravel()\n",
    "    dim_array[given_axis] = -1\n",
    "    # Reshape b with dim_array and perform elementwise multiplication with \n",
    "    # broadcasting along the singleton dimensions for the final output\n",
    "    image_sum_reshaped = image_sum.reshape(dim_array)\n",
    "    images = images*image_sum_reshaped*255\n",
    "\n",
    "    # make it rgb by duplicating 3 channels.\n",
    "    images = np.stack([images, images, images],axis=-1)\n",
    "    \n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import random\n",
    "\n",
    "datadir = \"/home/david/Storage/dataset_Tom/img224_all/converted/rotation_224_v1/\"\n",
    "num_train = 100  # Limit the number of images used in training to shorten epoch time\n",
    "\n",
    "train_files = glob.glob(os.path.join(datadir, 'train_file_*'))\n",
    "train_files = random.choice(train_files)  # Choose one of the training files to use (for now)\n",
    "\n",
    "# Open the chosen file and extract the dataset\n",
    "f = tables.open_file(train_files, 'r')\n",
    "a = np.array(f.root.img_pt) # Images\n",
    "b = np.array(f.root.label) # Labels\n",
    "# Randomly shuffle label and images, keep the indexing\n",
    "c = np.c_[a.reshape(len(a), -1), b.reshape(len(b), -1)]\n",
    "np.random.shuffle(c)\n",
    "train_images = c[:, :a.size//len(a)].reshape(a.shape)\n",
    "train_labels = c[:, a.size//len(a):].reshape(b.shape)\n",
    "\n",
    "# Limit the data set to make the notebook execute quickly.\n",
    "train_images = train_images[:num_train]\n",
    "train_labels = train_labels[:num_train]\n",
    "\n",
    "train_images = normalize_and_rgb(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = 100\n",
    "\n",
    "test_files = glob.glob(os.path.join(datadir, '/home/david/Storage/dataset_Tom/img224_all/converted/rotation_224_v1/test_file_*'))\n",
    "test_files = random.choice(test_files)  # Choose one of the training files to use (for now)\n",
    "\n",
    "# Open the chosen file and extract the dataset\n",
    "f = tables.open_file(test_files, 'r')\n",
    "a = np.array(f.root.img_pt) # Images\n",
    "b = np.array(f.root.label) # Labels\n",
    "# Randomly shuffle label and images, keep the indexing\n",
    "c = np.c_[a.reshape(len(a), -1), b.reshape(len(b), -1)]\n",
    "np.random.shuffle(c)\n",
    "test_images = c[:, :a.size//len(a)].reshape(a.shape)\n",
    "test_labels = c[:, a.size//len(a):].reshape(b.shape)\n",
    "\n",
    "# Limit the data set to make the notebook execute quickly.\n",
    "test_images = test_images[:num_test]\n",
    "test_labels = test_labels[:num_test]\n",
    "\n",
    "test_images = normalize_and_rgb(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images():\n",
    "    # Create a placeholder for our incoming images\n",
    "    in_images = tf.placeholder(tf.float32)\n",
    "    in_height = 64\n",
    "    in_width = 64\n",
    "    in_images.set_shape([None, in_height, in_width, 3])\n",
    "    \n",
    "    # Resize those images to fit our featurizer\n",
    "    out_width = 224\n",
    "    out_height = 224\n",
    "    image_tensors = tf.image.resize_images(in_images, [out_height,out_width])\n",
    "    image_tensors = tf.to_float(image_tensors)\n",
    "    \n",
    "    return in_images, image_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_classifier(in_tensor):\n",
    "    from keras.layers import Dropout, Dense, Flatten\n",
    "    K.set_session(tf.get_default_session())\n",
    "    \n",
    "    FC_SIZE = 1024\n",
    "    NUM_CLASSES = 2\n",
    "\n",
    "    x = Dropout(0.2, input_shape=(1, 1, 2048,))(in_tensor)\n",
    "    x = Dense(FC_SIZE, activation='relu', input_dim=(1, 1, 2048,))(x)\n",
    "    x = Flatten()(x)\n",
    "    preds = Dense(NUM_CLASSES, activation='softmax', input_dim=FC_SIZE, name='classifier_output')(x)\n",
    "    return preds\n",
    "\n",
    "def construct_model(quantized, starting_weights_directory = None):\n",
    "    \n",
    "    # Convert images to 3D tensors [width,height,channel]\n",
    "    in_images, image_tensors = preprocess_images()\n",
    "\n",
    "    # Construct featurizer using quantized or unquantized ResNet50 model\n",
    "    if not quantized:\n",
    "        featurizer = resnet50.ResNet50(data_format())\n",
    "    else:\n",
    "        #featurizer = QuantizedResnet50(saved_model_dir, custom_weights_directory = starting_weights_directory)\n",
    "        print(\"quantize mode disabled\")\n",
    "    features = featurizer\n",
    "    # Construct classifier\n",
    "    preds = construct_classifier(features(in_images, training=True))\n",
    "\n",
    "    # Initialize weights\n",
    "    sess = tf.get_default_session()\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    featurizer.restore_weights(sess)\n",
    "\n",
    "    return in_images, image_tensors, features, preds, featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_format():\n",
    "    return 'channels_last' if tf.test.is_gpu_available() else 'channels_first'\n",
    "\n",
    "def train_model(preds, in_images, train_images, train_labels, train_epoch = 10):\n",
    "    \"\"\" training model \"\"\"\n",
    "    from keras.objectives import binary_crossentropy\n",
    "    from keras.metrics import categorical_accuracy\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    learning_rate = 0.001 \n",
    "        \n",
    "    # Specify the loss function\n",
    "    in_labels = tf.placeholder(tf.float32, shape=(None, 2))   \n",
    "    cross_entropy = tf.reduce_mean(binary_crossentropy(in_labels, preds))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    \n",
    "    accuracy = tf.reduce_mean(categorical_accuracy(in_labels, preds))\n",
    "    auc = tf.metrics.auc(tf.cast(in_labels, tf.bool), preds)\n",
    "    \n",
    "    def chunks(a, b, n):\n",
    "        \"\"\"Yield successive n-sized chunks from a and b.\"\"\"\n",
    "        for i in range(0, num_train, n):\n",
    "            yield a[i:i + n], b[i:i + n]\n",
    "\n",
    "    chunk_size = 16\n",
    "    chunk_num = len(train_labels) / chunk_size\n",
    "\n",
    "    sess = tf.get_default_session()\n",
    "    sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    \n",
    "    loss_over_epoch = []\n",
    "    accuracy_over_epoch = []\n",
    "    auc_over_epoch = []\n",
    "    \n",
    "    for epoch in range(train_epoch):\n",
    "        avg_loss = 0\n",
    "        avg_accuracy = 0\n",
    "        avg_auc = 0\n",
    "        for img_chunk, label_chunk in tqdm(chunks(train_images, train_labels, chunk_size)):\n",
    "            _, loss = sess.run([optimizer, cross_entropy],\n",
    "                                feed_dict={in_images: img_chunk,\n",
    "                                           in_labels: label_chunk,\n",
    "                                           K.learning_phase(): 1})\n",
    "            avg_loss += loss / chunk_num\n",
    "            accuracy_result, auc_result = sess.run([accuracy, auc],\n",
    "                                     feed_dict={in_images: test_images,\n",
    "                                                in_labels: test_labels,\n",
    "                                                K.learning_phase(): 0})\n",
    "            avg_accuracy += accuracy_result / chunk_num\n",
    "            avg_auc += auc_result[1] / chunk_num\n",
    "        print(\"Epoch:\", (epoch + 1), \"loss = \", \"{:.3f}\".format(avg_loss))\n",
    "        print(\"Accuracy:\", \"{:.3f}\".format(avg_accuracy), \", Area under ROC curve:\", \"{:.3f}\".format(avg_auc))\n",
    "            \n",
    "        loss_over_epoch.append(avg_loss)\n",
    "        accuracy_over_epoch.append(avg_accuracy)\n",
    "        auc_over_epoch.append(avg_auc)\n",
    "            \n",
    "        # Reach desired performance\n",
    "        if (avg_loss < 0.001):\n",
    "            break\n",
    "            \n",
    "    return loss_over_epoch, accuracy_over_epoch, auc_over_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(preds, in_images, test_images, test_labels):\n",
    "    \"\"\"Test the model\"\"\"\n",
    "    from keras.metrics import categorical_accuracy\n",
    "\n",
    "    in_labels = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "    accuracy = tf.reduce_mean(categorical_accuracy(in_labels, preds))\n",
    "    auc = tf.metrics.auc(tf.cast(in_labels, tf.bool), preds)\n",
    "    \n",
    "    sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    accuracy, auc = sess.run([accuracy, auc],\n",
    "                    feed_dict={in_images: test_images,\n",
    "                               in_labels: test_labels,\n",
    "                               K.learning_phase(): 0})\n",
    "    \n",
    "    return accuracy, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /home/david/workplace/Top-tagging-keras/resnet50.py:357 call *\n        x = self.avg_pool(x)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:634 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/pooling.py:248 call\n        data_format=conv_utils.convert_data_format(self.data_format, 4))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py:3528 avg_pool\n        name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py:95 avg_pool\n        data_format=data_format, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:788 _apply_op_helper\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3616 create_op\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:2027 __init__\n        control_input_ops)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1867 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 7 from 2 for 'res_net50/average_pooling2d/AvgPool' (op: 'AvgPool') with input shapes: [?,2,2,2048].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-182ac1cf5937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0min_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss_over_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_over_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc_over_epoch\u001b[0m \u001b[0;34m=\u001b[0m         \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epoch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4a49f259d802>\u001b[0m in \u001b[0;36mconstruct_model\u001b[0;34m(quantized, starting_weights_directory)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeaturizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Construct classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Initialize weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /home/david/workplace/Top-tagging-keras/resnet50.py:357 call *\n        x = self.avg_pool(x)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:634 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/pooling.py:248 call\n        data_format=conv_utils.convert_data_format(self.data_format, 4))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py:3528 avg_pool\n        name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py:95 avg_pool\n        data_format=data_format, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:788 _apply_op_helper\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:507 new_func\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3616 create_op\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:2027 __init__\n        control_input_ops)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1867 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Negative dimension size caused by subtracting 7 from 2 for 'res_net50/average_pooling2d/AvgPool' (op: 'AvgPool') with input shapes: [?,2,2,2048].\n"
     ]
    }
   ],
   "source": [
    "# Launch the training\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "\n",
    "num_epoch_train = 10\n",
    "\n",
    "with sess.as_default():\n",
    "    in_images, image_tensors, features, preds, featurizer = construct_model(quantized=False)\n",
    "    loss_over_epoch, accuracy_over_epoch, auc_over_epoch = \\\n",
    "        train_model(preds, in_images, train_images, train_labels, train_epoch=num_epoch_train)    \n",
    "    accuracy, auc = test_model(preds, in_images, test_images, test_labels)  \n",
    "    # print(\"Accuracy:\", accuracy, \", Area under ROC curve:\", auc)\n",
    "    featurizer.save_weights(saved_model_dir + \"/rn50/1.1.3/resnet50_bw\", tf.get_default_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
